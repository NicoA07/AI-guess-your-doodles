{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Libraries**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow import keras \n",
    "from keras.layers import Dense,Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "from shutil import copyfile\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Processing the Dataset**\n",
    "____\n",
    "<!-- > Here we ....\n",
    "\n",
    "<img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\" title=\"Python Logo\"/>\n",
    "\n",
    "[Wikipedia Link](https://en.wikipedia.org \"Wikipedia\")\n",
    "<br>\n",
    "<span style=\"color:White\">Text</span> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset List :  ['Trained Dataset\\\\angel.npy', 'Trained Dataset\\\\ant.npy', 'Trained Dataset\\\\apple.npy', 'Trained Dataset\\\\axe.npy', 'Trained Dataset\\\\backpack.npy', 'Trained Dataset\\\\banana.npy', 'Trained Dataset\\\\bandage.npy', 'Trained Dataset\\\\baseball_bat.npy', 'Trained Dataset\\\\basketball.npy', 'Trained Dataset\\\\bathtub.npy', 'Trained Dataset\\\\bear.npy', 'Trained Dataset\\\\beard.npy', 'Trained Dataset\\\\bee.npy', 'Trained Dataset\\\\bicycle.npy', 'Trained Dataset\\\\binoculars.npy', 'Trained Dataset\\\\bird.npy', 'Trained Dataset\\\\birthday_cake.npy', 'Trained Dataset\\\\book.npy', 'Trained Dataset\\\\boomerang.npy', 'Trained Dataset\\\\bowtie.npy', 'Trained Dataset\\\\bracelet.npy', 'Trained Dataset\\\\brain.npy', 'Trained Dataset\\\\bread.npy', 'Trained Dataset\\\\bridge.npy', 'Trained Dataset\\\\broccoli.npy', 'Trained Dataset\\\\broom.npy', 'Trained Dataset\\\\bucket.npy', 'Trained Dataset\\\\bus.npy', 'Trained Dataset\\\\bush.npy', 'Trained Dataset\\\\butterfly.npy', 'Trained Dataset\\\\cactus.npy', 'Trained Dataset\\\\calendar.npy', 'Trained Dataset\\\\camera.npy', 'Trained Dataset\\\\campfire.npy', 'Trained Dataset\\\\candle.npy', 'Trained Dataset\\\\car.npy', 'Trained Dataset\\\\carrot.npy', 'Trained Dataset\\\\cat.npy', 'Trained Dataset\\\\cell_phone.npy', 'Trained Dataset\\\\chair.npy', 'Trained Dataset\\\\circle.npy', 'Trained Dataset\\\\coffee_cup.npy', 'Trained Dataset\\\\diamond.npy', 'Trained Dataset\\\\dog.npy', 'Trained Dataset\\\\donut.npy', 'Trained Dataset\\\\door.npy', 'Trained Dataset\\\\duck.npy', 'Trained Dataset\\\\dumbbell.npy', 'Trained Dataset\\\\ear.npy', 'Trained Dataset\\\\elephant.npy', 'Trained Dataset\\\\envelope.npy', 'Trained Dataset\\\\eyeglasses.npy', 'Trained Dataset\\\\fish.npy', 'Trained Dataset\\\\flower.npy', 'Trained Dataset\\\\fork.npy', 'Trained Dataset\\\\grapes.npy', 'Trained Dataset\\\\guitar.npy', 'Trained Dataset\\\\hammer.npy', 'Trained Dataset\\\\hot_air_balloon.npy', 'Trained Dataset\\\\house.npy', 'Trained Dataset\\\\ice_cream.npy', 'Trained Dataset\\\\key.npy', 'Trained Dataset\\\\knife.npy', 'Trained Dataset\\\\ladder.npy', 'Trained Dataset\\\\lantern.npy', 'Trained Dataset\\\\laptop.npy', 'Trained Dataset\\\\light_bulb.npy', 'Trained Dataset\\\\moon.npy', 'Trained Dataset\\\\mug.npy', 'Trained Dataset\\\\octagon.npy', 'Trained Dataset\\\\panda.npy', 'Trained Dataset\\\\pear.npy', 'Trained Dataset\\\\peas.npy', 'Trained Dataset\\\\pencil.npy', 'Trained Dataset\\\\pig.npy', 'Trained Dataset\\\\pineapple.npy', 'Trained Dataset\\\\pizza.npy', 'Trained Dataset\\\\rainbow.npy', 'Trained Dataset\\\\sailboat.npy', 'Trained Dataset\\\\scissors.npy', 'Trained Dataset\\\\sea_turtle.npy', 'Trained Dataset\\\\shoe.npy', 'Trained Dataset\\\\smiley_face.npy', 'Trained Dataset\\\\snail.npy', 'Trained Dataset\\\\snowman.npy', 'Trained Dataset\\\\sock.npy', 'Trained Dataset\\\\spider.npy', 'Trained Dataset\\\\spoon.npy', 'Trained Dataset\\\\square.npy', 'Trained Dataset\\\\star.npy', 'Trained Dataset\\\\stethoscope.npy', 'Trained Dataset\\\\strawberry.npy', 'Trained Dataset\\\\sun.npy', 'Trained Dataset\\\\sword.npy', 'Trained Dataset\\\\tiger.npy', 'Trained Dataset\\\\tree.npy', 'Trained Dataset\\\\triangle.npy', 'Trained Dataset\\\\washing_machine.npy', 'Trained Dataset\\\\watermelon.npy', 'Trained Dataset\\\\windmill.npy']\n",
      "Number of Categories :  100\n",
      "valid samples 50000\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(directory):\n",
    "    # Variables\n",
    "    sample_size_per_category = 5000\n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    mylist = []\n",
    "    \n",
    "    # Load all .npy files into our dataset\n",
    "    dataset = glob.glob(os.path.join(directory, '*.npy'))\n",
    "    print(\"Dataset List : \", dataset)\n",
    "\n",
    "    # Load each file in the dataset\n",
    "    for idx, file in enumerate(dataset):\n",
    "        data = np.load(file)\n",
    "        data = data[0: sample_size_per_category, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        categories_list, ext = os.path.splitext(os.path.basename(file))\n",
    "        mylist.append(categories_list)\n",
    "    \n",
    "    return x, y, mylist \n",
    "\n",
    "# Randomize the data\n",
    "def random_data(datax, datay):\n",
    "    permutation = np.random.permutation(datay.shape[0])\n",
    "    x = datax[permutation, :]\n",
    "    y = datay[permutation]\n",
    "    return x, y\n",
    "    \n",
    "    \n",
    "#Seperate dataset to training data and testing data\n",
    "def train_test_split(datax, datay, ratio = 0.1):\n",
    "    validations_samples  = int(datax.shape[0] / 100 * (ratio * 100))\n",
    "    print(\"valid samples\", validations_samples)\n",
    "    x_test  = datax[0:validations_samples, :]\n",
    "    y_test  = datay[0:validations_samples]\n",
    "    x_train = datax[validations_samples:datax.shape[0], :]\n",
    "    y_train = datay[validations_samples:datay.shape[0]]\n",
    "\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def data_preprocessing(datax_train, datax_test):\n",
    "    x_train = datax_train.reshape(datax_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    x_test  =  datax_test.reshape(datax_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "\n",
    "    return x_train, x_test\n",
    "\n",
    "def data_encoding(datay_train, datay_test, data_category):\n",
    "    y_train = keras.utils.to_categorical(datay_train, len(data_category))\n",
    "    y_test  = keras.utils.to_categorical(datay_test, len(data_category))\n",
    "\n",
    "    return y_train, y_test\n",
    "    \n",
    "yourdirectory = 'Trained Dataset'\n",
    "x, y, categories_list = load_dataset(yourdirectory)\n",
    "print(\"Number of Categories : \" ,len(categories_list))\n",
    "x, y = random_data(x, y)\n",
    "x_train, y_train, x_test, y_test = train_test_split(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Test**\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   2.  78. 115. 136.  98.   2.\n",
      "   19.  85. 153. 157.  18.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   9.  66.  82. 203. 255. 255. 245. 255. 241.\n",
      "  253. 255. 234. 245. 184.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  16. 237. 255. 255. 239. 174.  65. 208. 245. 205.\n",
      "  117.  81.  64. 102. 255.  88.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0. 132. 255. 138. 116. 236. 245. 240. 236. 170.  10.\n",
      "    0. 169. 255. 244. 235. 236. 170. 178. 141.  21.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0. 181. 254.  45.  60.   0. 111. 255. 226. 255. 225.\n",
      "   48.   7.  71. 139. 243. 248. 209. 203. 248. 206.   0.   0.   0.   0.]\n",
      " [  0.   0.   5.  89. 184. 247. 255. 244.   4.  73. 255.  80.  68. 250.\n",
      "  140.   0.   0.   0.  50. 248. 126.   0. 102. 255.  41.   0.   0.   0.]\n",
      " [  0.  20. 197. 255. 230. 164.  97.  26.  13. 156. 255.  88. 145. 255.\n",
      "   89.   0.   0.   0.   0. 103.  56.   0.  20. 251. 231. 105.   0.   0.]\n",
      " [  0. 108. 255. 151.  66.  79. 164.  82. 100. 249. 128.   2. 211. 255.\n",
      "  245.  97.   0.   0.   0.   0.   0.   0.   0.  89. 184. 255.  84.   0.]\n",
      " [  0.  44. 218. 255. 255. 255. 243. 109.   2.  19.   0.   0.   3. 101.\n",
      "  244. 187.  26.   0.   0.   0.   0.   0.   0.   3.  64. 255. 122.   0.]\n",
      " [  0.   0.   6.  64. 187. 236.  34.   0.   0.   9. 176.  83.   9. 249.\n",
      "  252. 255. 255. 224. 204. 203. 187. 187. 203. 238. 255. 230.  47.   0.]\n",
      " [  0.   0.   0.   0. 165. 241. 187. 187. 198. 247. 255. 249. 251. 255.\n",
      "  255. 204. 105. 159. 170. 179. 187. 187. 173. 146.  76.  10.   0.   0.]\n",
      " [  0.   0.   0.   0.  33. 180. 187. 187. 183. 133.  74. 173. 220. 211.\n",
      "  118.  17.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "category:  brain\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = randint(0, len(x_train))\n",
    "print(x_train[idx].reshape(28,28))\n",
    "plt.imshow(x_train[idx].reshape(28,28)) \n",
    "print(\"category: \", categories_list[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Preprocessing**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = data_preprocessing(x_train, x_test)\n",
    "y_train, y_test = data_encoding(y_train, y_test, categories_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN MODEL**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               295424    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 418,516\n",
      "Trainable params: 418,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Our CNN Model\n",
    "# Number of Categories in our Dataset\n",
    "Num_of_Category = 100\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(16, (3, 3),padding='same',input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(Conv2D(16, (3, 3),padding='same',input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dense(Num_of_Category, activation='softmax')) ### NUMBER OF Category\n",
    "\n",
    "# Compiling model\n",
    "adam = tf.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['top_k_categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Model Training**\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1583/1583 - 213s - loss: 1.5083 - top_k_categorical_accuracy: 0.8434 - val_loss: 1.0356 - val_top_k_categorical_accuracy: 0.9129 - 213s/epoch - 134ms/step\n",
      "Epoch 2/50\n",
      "1583/1583 - 215s - loss: 0.9503 - top_k_categorical_accuracy: 0.9226 - val_loss: 0.9043 - val_top_k_categorical_accuracy: 0.9262 - 215s/epoch - 136ms/step\n",
      "Epoch 3/50\n",
      "1583/1583 - 217s - loss: 0.8268 - top_k_categorical_accuracy: 0.9354 - val_loss: 0.8510 - val_top_k_categorical_accuracy: 0.9321 - 217s/epoch - 137ms/step\n",
      "Epoch 4/50\n",
      "1583/1583 - 217s - loss: 0.7539 - top_k_categorical_accuracy: 0.9424 - val_loss: 0.7754 - val_top_k_categorical_accuracy: 0.9401 - 217s/epoch - 137ms/step\n",
      "Epoch 5/50\n",
      "1583/1583 - 217s - loss: 0.7067 - top_k_categorical_accuracy: 0.9471 - val_loss: 0.7750 - val_top_k_categorical_accuracy: 0.9388 - 217s/epoch - 137ms/step\n",
      "Epoch 6/50\n",
      "1583/1583 - 222s - loss: 0.6669 - top_k_categorical_accuracy: 0.9507 - val_loss: 0.7523 - val_top_k_categorical_accuracy: 0.9417 - 222s/epoch - 140ms/step\n",
      "Epoch 7/50\n",
      "1583/1583 - 221s - loss: 0.6374 - top_k_categorical_accuracy: 0.9538 - val_loss: 0.7543 - val_top_k_categorical_accuracy: 0.9408 - 221s/epoch - 140ms/step\n",
      "Epoch 8/50\n",
      "1583/1583 - 221s - loss: 0.6095 - top_k_categorical_accuracy: 0.9564 - val_loss: 0.7374 - val_top_k_categorical_accuracy: 0.9425 - 221s/epoch - 140ms/step\n",
      "Epoch 9/50\n",
      "1583/1583 - 220s - loss: 0.5899 - top_k_categorical_accuracy: 0.9582 - val_loss: 0.7360 - val_top_k_categorical_accuracy: 0.9431 - 220s/epoch - 139ms/step\n",
      "Epoch 10/50\n",
      "1583/1583 - 221s - loss: 0.5685 - top_k_categorical_accuracy: 0.9607 - val_loss: 0.7335 - val_top_k_categorical_accuracy: 0.9434 - 221s/epoch - 139ms/step\n",
      "Epoch 11/50\n",
      "1583/1583 - 222s - loss: 0.5523 - top_k_categorical_accuracy: 0.9621 - val_loss: 0.7502 - val_top_k_categorical_accuracy: 0.9404 - 222s/epoch - 141ms/step\n",
      "Epoch 12/50\n",
      "1583/1583 - 220s - loss: 0.5380 - top_k_categorical_accuracy: 0.9634 - val_loss: 0.7674 - val_top_k_categorical_accuracy: 0.9398 - 220s/epoch - 139ms/step\n",
      "Epoch 13/50\n",
      "1583/1583 - 221s - loss: 0.5224 - top_k_categorical_accuracy: 0.9651 - val_loss: 0.7499 - val_top_k_categorical_accuracy: 0.9416 - 221s/epoch - 139ms/step\n",
      "Epoch 14/50\n",
      "1583/1583 - 221s - loss: 0.5108 - top_k_categorical_accuracy: 0.9663 - val_loss: 0.7801 - val_top_k_categorical_accuracy: 0.9393 - 221s/epoch - 140ms/step\n",
      "Epoch 15/50\n",
      "1583/1583 - 222s - loss: 0.4980 - top_k_categorical_accuracy: 0.9674 - val_loss: 0.7420 - val_top_k_categorical_accuracy: 0.9433 - 222s/epoch - 140ms/step\n",
      "Epoch 16/50\n",
      "1583/1583 - 221s - loss: 0.4858 - top_k_categorical_accuracy: 0.9689 - val_loss: 0.7686 - val_top_k_categorical_accuracy: 0.9415 - 221s/epoch - 140ms/step\n",
      "Epoch 17/50\n",
      "1583/1583 - 222s - loss: 0.4758 - top_k_categorical_accuracy: 0.9698 - val_loss: 0.7714 - val_top_k_categorical_accuracy: 0.9424 - 222s/epoch - 140ms/step\n",
      "Epoch 18/50\n",
      "1583/1583 - 222s - loss: 0.4656 - top_k_categorical_accuracy: 0.9711 - val_loss: 0.7909 - val_top_k_categorical_accuracy: 0.9410 - 222s/epoch - 140ms/step\n",
      "Epoch 19/50\n",
      "1583/1583 - 223s - loss: 0.4592 - top_k_categorical_accuracy: 0.9716 - val_loss: 0.7714 - val_top_k_categorical_accuracy: 0.9415 - 223s/epoch - 141ms/step\n",
      "Epoch 20/50\n",
      "1583/1583 - 222s - loss: 0.4489 - top_k_categorical_accuracy: 0.9726 - val_loss: 0.7869 - val_top_k_categorical_accuracy: 0.9418 - 222s/epoch - 140ms/step\n",
      "Epoch 21/50\n",
      "1583/1583 - 223s - loss: 0.4421 - top_k_categorical_accuracy: 0.9732 - val_loss: 0.8048 - val_top_k_categorical_accuracy: 0.9394 - 223s/epoch - 141ms/step\n",
      "Epoch 22/50\n",
      "1583/1583 - 217s - loss: 0.4372 - top_k_categorical_accuracy: 0.9742 - val_loss: 0.7932 - val_top_k_categorical_accuracy: 0.9398 - 217s/epoch - 137ms/step\n",
      "Epoch 23/50\n",
      "1583/1583 - 214s - loss: 0.4261 - top_k_categorical_accuracy: 0.9751 - val_loss: 0.7969 - val_top_k_categorical_accuracy: 0.9402 - 214s/epoch - 135ms/step\n",
      "Epoch 24/50\n",
      "1583/1583 - 214s - loss: 0.4237 - top_k_categorical_accuracy: 0.9752 - val_loss: 0.8113 - val_top_k_categorical_accuracy: 0.9398 - 214s/epoch - 135ms/step\n",
      "Epoch 25/50\n",
      "1583/1583 - 213s - loss: 0.4139 - top_k_categorical_accuracy: 0.9762 - val_loss: 0.8150 - val_top_k_categorical_accuracy: 0.9404 - 213s/epoch - 135ms/step\n",
      "Epoch 26/50\n",
      "1583/1583 - 211s - loss: 0.4112 - top_k_categorical_accuracy: 0.9769 - val_loss: 0.8275 - val_top_k_categorical_accuracy: 0.9391 - 211s/epoch - 133ms/step\n",
      "Epoch 27/50\n",
      "1583/1583 - 212s - loss: 0.4061 - top_k_categorical_accuracy: 0.9772 - val_loss: 0.8197 - val_top_k_categorical_accuracy: 0.9402 - 212s/epoch - 134ms/step\n",
      "Epoch 28/50\n",
      "1583/1583 - 212s - loss: 0.3986 - top_k_categorical_accuracy: 0.9780 - val_loss: 0.8240 - val_top_k_categorical_accuracy: 0.9403 - 212s/epoch - 134ms/step\n",
      "Epoch 29/50\n",
      "1583/1583 - 221s - loss: 0.3956 - top_k_categorical_accuracy: 0.9784 - val_loss: 0.8260 - val_top_k_categorical_accuracy: 0.9395 - 221s/epoch - 139ms/step\n",
      "Epoch 30/50\n",
      "1583/1583 - 215s - loss: 0.3897 - top_k_categorical_accuracy: 0.9791 - val_loss: 0.8499 - val_top_k_categorical_accuracy: 0.9381 - 215s/epoch - 136ms/step\n",
      "Epoch 31/50\n",
      "1583/1583 - 218s - loss: 0.3887 - top_k_categorical_accuracy: 0.9791 - val_loss: 0.8776 - val_top_k_categorical_accuracy: 0.9361 - 218s/epoch - 138ms/step\n",
      "Epoch 32/50\n",
      "1583/1583 - 215s - loss: 0.3822 - top_k_categorical_accuracy: 0.9797 - val_loss: 0.8497 - val_top_k_categorical_accuracy: 0.9390 - 215s/epoch - 136ms/step\n",
      "Epoch 33/50\n",
      "1583/1583 - 216s - loss: 0.3792 - top_k_categorical_accuracy: 0.9801 - val_loss: 0.8481 - val_top_k_categorical_accuracy: 0.9389 - 216s/epoch - 136ms/step\n",
      "Epoch 34/50\n",
      "1583/1583 - 216s - loss: 0.3734 - top_k_categorical_accuracy: 0.9807 - val_loss: 0.8669 - val_top_k_categorical_accuracy: 0.9379 - 216s/epoch - 137ms/step\n",
      "Epoch 35/50\n",
      "1583/1583 - 217s - loss: 0.3735 - top_k_categorical_accuracy: 0.9808 - val_loss: 0.8647 - val_top_k_categorical_accuracy: 0.9365 - 217s/epoch - 137ms/step\n",
      "Epoch 36/50\n",
      "1583/1583 - 218s - loss: 0.3673 - top_k_categorical_accuracy: 0.9812 - val_loss: 0.8788 - val_top_k_categorical_accuracy: 0.9369 - 218s/epoch - 138ms/step\n",
      "Epoch 37/50\n",
      "1583/1583 - 217s - loss: 0.3646 - top_k_categorical_accuracy: 0.9818 - val_loss: 0.8731 - val_top_k_categorical_accuracy: 0.9391 - 217s/epoch - 137ms/step\n",
      "Epoch 38/50\n",
      "1583/1583 - 218s - loss: 0.3601 - top_k_categorical_accuracy: 0.9824 - val_loss: 0.8718 - val_top_k_categorical_accuracy: 0.9377 - 218s/epoch - 137ms/step\n",
      "Epoch 39/50\n",
      "1583/1583 - 222s - loss: 0.3575 - top_k_categorical_accuracy: 0.9824 - val_loss: 0.8885 - val_top_k_categorical_accuracy: 0.9359 - 222s/epoch - 140ms/step\n",
      "Epoch 40/50\n",
      "1583/1583 - 221s - loss: 0.3547 - top_k_categorical_accuracy: 0.9828 - val_loss: 0.8916 - val_top_k_categorical_accuracy: 0.9371 - 221s/epoch - 140ms/step\n",
      "Epoch 41/50\n",
      "1583/1583 - 215s - loss: 0.3548 - top_k_categorical_accuracy: 0.9828 - val_loss: 0.8933 - val_top_k_categorical_accuracy: 0.9361 - 215s/epoch - 136ms/step\n",
      "Epoch 42/50\n",
      "1583/1583 - 214s - loss: 0.3521 - top_k_categorical_accuracy: 0.9830 - val_loss: 0.9086 - val_top_k_categorical_accuracy: 0.9363 - 214s/epoch - 135ms/step\n",
      "Epoch 43/50\n",
      "1583/1583 - 217s - loss: 0.3483 - top_k_categorical_accuracy: 0.9835 - val_loss: 0.8982 - val_top_k_categorical_accuracy: 0.9367 - 217s/epoch - 137ms/step\n",
      "Epoch 44/50\n",
      "1583/1583 - 215s - loss: 0.3434 - top_k_categorical_accuracy: 0.9838 - val_loss: 0.9241 - val_top_k_categorical_accuracy: 0.9352 - 215s/epoch - 136ms/step\n",
      "Epoch 45/50\n",
      "1583/1583 - 211s - loss: 0.3426 - top_k_categorical_accuracy: 0.9840 - val_loss: 0.9031 - val_top_k_categorical_accuracy: 0.9370 - 211s/epoch - 133ms/step\n",
      "Epoch 46/50\n",
      "1583/1583 - 214s - loss: 0.3385 - top_k_categorical_accuracy: 0.9842 - val_loss: 0.9125 - val_top_k_categorical_accuracy: 0.9376 - 214s/epoch - 135ms/step\n",
      "Epoch 47/50\n",
      "1583/1583 - 213s - loss: 0.3363 - top_k_categorical_accuracy: 0.9848 - val_loss: 0.9196 - val_top_k_categorical_accuracy: 0.9361 - 213s/epoch - 134ms/step\n",
      "Epoch 48/50\n",
      "1583/1583 - 218s - loss: 0.3350 - top_k_categorical_accuracy: 0.9849 - val_loss: 0.9262 - val_top_k_categorical_accuracy: 0.9355 - 218s/epoch - 137ms/step\n",
      "Epoch 49/50\n",
      "1583/1583 - 219s - loss: 0.3314 - top_k_categorical_accuracy: 0.9851 - val_loss: 0.9299 - val_top_k_categorical_accuracy: 0.9356 - 219s/epoch - 139ms/step\n",
      "Epoch 50/50\n",
      "1583/1583 - 220s - loss: 0.3310 - top_k_categorical_accuracy: 0.9851 - val_loss: 0.9307 - val_top_k_categorical_accuracy: 0.9359 - 220s/epoch - 139ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ded5323700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, validation_split = 0.1, batch_size = 256, verbose = 2, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Evaluation for Model Accuracy**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.9153 - top_k_categorical_accuracy: 0.9379\n",
      "Test accuarcy: 93.79%\n"
     ]
    }
   ],
   "source": [
    "percentage = model.evaluate(x_test, y_test, verbose = 1)\n",
    "print('Test accuracy: {:0.2f}%'.format(percentage[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the Inference**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 183ms/step\n",
      "['backpack', 'butterfly', 'elephant', 'basketball', 'mug']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = randint(0, len(x_test))\n",
    "img = x_test[idx]\n",
    "plt.imshow(img.squeeze()) \n",
    "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "ind = (-pred).argsort()[:5]\n",
    "latex = [categories_list[x] for x in ind]\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving The Model**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('finalmodel100.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting the Model**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "from os import path\n",
    "path = r\"D:\\Documents\\National Chiao Tung University\\Intro to Artificial Intelligence\\Github Submit\"\n",
    "newFolderName=\"finalsubmission\"\n",
    "try:\n",
    "    os.mkdir(os.path.join(path, newFolderName))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "# myjsonmodel = model.to_json()\n",
    "# with open(\"testjsonbaru.json\", \"w\") as json_file:\n",
    "#     json_file.write(myjsonmodel)\n",
    "tfjs.converters.save_keras_model(model,os.path.join(path, newFolderName))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file model already exists.\n",
      "2022-06-14 16:27:43.620281: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-06-14 16:27:43.620505: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# !mkdir model\n",
    "# !tensorflowjs_converter --input_format keras modeledited40.h5 model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy class_names.txt model/class_names.txt\n",
    "# import shutil\n",
    "\n",
    "# source = r\"D:\\Documents\\National Chiao Tung University\\Intro to Artificial Intelligence\\Github Submit\\categories_list.txt\"\n",
    "# destination = r\"D:\\Documents\\National Chiao Tung University\\Intro to Artificial Intelligence\\Github Submit\\model\\categories_list.txt\"\n",
    "# shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy class_names.txt model/class_names.txt\n",
    "# import shutil\n",
    "# source = r\"D:\\Documents\\National Chiao Tung University\\Intro to Artificial Intelligence\\Final Project\\class_names.txt\"\n",
    "# destination = r\"D:\\Documents\\National Chiao Tung University\\Intro to Artificial Intelligence\\Final Project\\model\\class_names.txt\"\n",
    "# shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from http.server import BaseHTTPServer, BaseHTTPRequestHandlerimport\n",
    "# import ssl\n",
    "\n",
    "# httpd = BaseHTTPServer.HTTPServer(('localhost', 4443), SimpleHTTPServer.SimpleHTTPRequestHandler)\n",
    "# httpd.socket = ssl.wrap_socket (httpd.socket, certfile='./server.pem', server_side=True)\n",
    "# httpd.serve_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
